{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "w2v = KeyedVectors.load_word2vec_format('glove.6B.100d.bin.word2vec', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 71514\n",
      "W2V vocab size: 400000\n"
     ]
    }
   ],
   "source": [
    "import util\n",
    "words = util.load_vocab(\"fixed_vocab.pkl\")\n",
    "vocab_size = len(words)\n",
    "print(\"Vocab size:\", vocab_size)\n",
    "print(\"W2V vocab size:\", len(w2v.vocab))\n",
    "word2idx = { word:i for i,word in enumerate(words) }\n",
    "idx2word = { i:word for i,word in enumerate(words) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "songs = []\n",
    "with open(\"data/sentences.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        songs.append(line.rstrip().split(\" \"))\n",
    "shuffle(songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of songs: 57650\n",
      "Number of songs for training: 40355\n",
      "Number of songs for dev/test: 8647\n"
     ]
    }
   ],
   "source": [
    "song_count = len(songs)\n",
    "train_size = int(song_count * 0.7)\n",
    "test_dev_size = int((song_count - train_size) * 0.5)\n",
    "print(\"Total number of songs:\", song_count)\n",
    "print(\"Number of songs for training:\", train_size)\n",
    "print(\"Number of songs for dev/test:\", test_dev_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 40355\n",
      "Dev: 8647\n",
      "Test: 8648\n"
     ]
    }
   ],
   "source": [
    "songs_train = songs[:train_size]\n",
    "songs_dev = songs[train_size:train_size+test_dev_size]\n",
    "songs_test = songs[train_size+test_dev_size:]\n",
    "print(\"Train:\", len(songs_train))\n",
    "print(\"Dev:\", len(songs_dev))\n",
    "print(\"Test:\", len(songs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_14 (LSTM)               (None, 6, 128)            118784    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 6, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 1024)              4722688   \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 2048)              2099200   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 71514)             146532186 \n",
      "=================================================================\n",
      "Total params: 153,472,858\n",
      "Trainable params: 153,472,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Embedding, Dropout, GRU, Bidirectional\n",
    "from keras.layers import LeakyReLU\n",
    "import util\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"weights_word_{epoch:01d}.h5\",\n",
    "    monitor='loss',\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    period=1,\n",
    "    save_weights_only=True)\n",
    "\n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "\n",
    "SEQUENCE_LENGTH = 6\n",
    "\n",
    "def build_model1(vocab_size, sequence_length, embedding_size):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(sequence_length, embedding_size), return_sequences=True))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(LSTM(1024))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(2048))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dense(vocab_size, activation='softmax'))\n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer=\"rmsprop\", metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "embedding_size = w2v.vector_size + util.EMBEDDING_EXT\n",
    "model1 = build_model1(vocab_size, SEQUENCE_LENGTH, embedding_size)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_song(song, buffer_length):\n",
    "    tokens = song\n",
    "\n",
    "    x_train, y_train = [], []\n",
    "    for i in range(0, len(song)):\n",
    "        if i+buffer_length+1 >= len(tokens):\n",
    "            #pad_length = (i+buffer_length+1) - len(tokens)\n",
    "            #tokens += ['<pad>'] * pad_length\n",
    "            continue\n",
    "            \n",
    "        xs = tokens[i:i+buffer_length]\n",
    "        y = tokens[i+buffer_length]\n",
    "        discard = False\n",
    "        for x in xs:\n",
    "            if x not in words:\n",
    "                #print(\"Nope on\", x)\n",
    "                discard = True\n",
    "                break\n",
    "        if discard or y not in words:\n",
    "            continue\n",
    "            \n",
    "        x_train.append(xs)\n",
    "        y_train.append(y)\n",
    "\n",
    "    return x_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "\n",
    "def generate_batches(songs, sequence_length, batch_size):\n",
    "    x_train, y_train = [], []\n",
    "    for song in songs:\n",
    "        xs, ys = tokenize_song(song, sequence_length)\n",
    "        x_train.extend(xs)\n",
    "        y_train.extend(ys)\n",
    "        if len(x_train) >= batch_size:\n",
    "            yield x_train[0:batch_size], y_train[0:batch_size]\n",
    "\n",
    "            x_train = x_train[batch_size:]\n",
    "            y_train = y_train[batch_size:]\n",
    "    if len(x_train) > 0:\n",
    "        yield x_train, y_train\n",
    "        \n",
    "def generate_samples(songs, sequence_length, batch_size):\n",
    "    while True:\n",
    "        for xs_batch, ys_batch in generate_batches(songs, sequence_length, batch_size):\n",
    "            #c = list(zip(xs_batch, ys_batch))\n",
    "            #shuffle(c)\n",
    "            #xs_batch, ys_batch = zip(*c)\n",
    "\n",
    "            batch_size = len(xs_batch)\n",
    "            x_train = np.zeros((batch_size, sequence_length, embedding_size))\n",
    "            y_train = np.zeros((batch_size, ))\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                x_train[i] = util.encode_word_sequence(xs_batch[i], w2v)\n",
    "                y_train[i] = word2idx[ys_batch[i]]\n",
    "                \n",
    "            yield x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngrams(batch_size, sequence_length):\n",
    "    with open(\"prep.txt\", \"r\") as f:\n",
    "        x_train = np.zeros((batch_size, sequence_length, embedding_size))\n",
    "        y_train = np.zeros((batch_size, ))\n",
    "        i = 0\n",
    "        for line in f:\n",
    "            nums = line.split(\" \")\n",
    "            xs = list(map(lambda x: idx2word[x], map(int, nums[:6])))\n",
    "            xs = util.encode_word_sequence(xs, w2v)\n",
    "            y = int(nums[-1])\n",
    "            x_train[i] = xs\n",
    "            y_train[i] = y\n",
    "            if i % batch_size == 0:\n",
    "                yield x_train, y_train\n",
    "                i = 0\n",
    "            else:\n",
    "                i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 103) (8,)\n"
     ]
    }
   ],
   "source": [
    "sampler = generate_samples(songs_train, SEQUENCE_LENGTH, 8)\n",
    "x_batch, y_batch = next(sampler)\n",
    "print(x_batch.shape, y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., epochs=4, callbacks=[<keras.ca..., steps_per_epoch=100)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[2048,71514] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node training_5/RMSprop/mul_26}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-38e745b98e19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2048,71514] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node training_5/RMSprop/mul_26}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "model1.fit_generator(generate_ngrams(64, 6), samples_per_epoch=100, epochs=4, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev, y_dev = [], []\n",
    "for song in songs_dev[:5000]:\n",
    "    xs, ys = tokenize_song(song, SEQUENCE_LENGTH)\n",
    "    x_dev.extend(xs)\n",
    "    y_dev.extend(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'exposed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-bbd24ead818b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mlikelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mperplexity\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'exposed'"
     ]
    }
   ],
   "source": [
    "devset = list(zip(x_dev, y_dev))\n",
    "shuffle(devset)\n",
    "avg_perplexity = 0\n",
    "buffer_length = 1000\n",
    "idx = 0\n",
    "\n",
    "for i in range(4):\n",
    "\n",
    "    perplexity = 0.0\n",
    "    for x, y in devset[idx:idx+buffer_length]:\n",
    "        enc_seq = util.encode_word_sequence(x, w2v).reshape(1, SEQUENCE_LENGTH, embedding_size)\n",
    "        preds = model1.predict(enc_seq)[0]\n",
    "\n",
    "        likelihood = preds[word2idx[y]]\n",
    "        perplexity += np.log2(likelihood)\n",
    "        \n",
    "    perplexity = np.power(2, perplexity * -1/buffer_length)\n",
    "    print(\"Perpl:\", perplexity)\n",
    "    avg_perplexity += perplexity\n",
    "    idx += buffer_length\n",
    "\n",
    "print(\"Avg perpl:\", avg_perplexity / 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/Desktop/genius/util.py:115: RuntimeWarning: divide by zero encountered in log\n",
      "  log_preds_scaled = np.log(arr) / temperature\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "look at her face, it 68th swordplay \n",
      "babe garry muscatel lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense lense\n"
     ]
    }
   ],
   "source": [
    "words = [\"look\", \"at\", \"her\", \"face\", \",\", \"it\"]\n",
    "#words = [\"when\", \"there\", \"'s\", \"a\", \"dark\", \"storm\"]\n",
    "#words = [\"do\", \"better\", \",\", \"who\", \"better\", \"?\"]\n",
    "words_seq = util.encode_word_sequence(words, w2v).reshape(1, SEQUENCE_LENGTH, embedding_size)\n",
    "#print(' '.join([decode_vec(words[0][i], w2v) for i in range(SEQUENCE_LENGTH)]))\n",
    "\n",
    "result = words\n",
    "for j in range(60):\n",
    "    word = idx2word[util.sample(model1.predict(words_seq))]\n",
    "    #word = one_hot_decode(model.predict(words_seq), idx2word)\n",
    "    result.append(word)\n",
    "    \n",
    "    new_words = np.zeros((1, SEQUENCE_LENGTH, embedding_size))\n",
    "    for i in range(SEQUENCE_LENGTH-1):\n",
    "        new_words[0, i] = words_seq[0, i+1]\n",
    "    new_words[0, SEQUENCE_LENGTH-1] = util.encode_word(word, w2v)\n",
    "    words_seq = new_words\n",
    "\n",
    "#print(' '.join([decode_vec(words[0][i], w2v) for i in range(SEQUENCE_LENGTH)]))\n",
    "\n",
    "print(util.textify(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
