{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face  \\nAnd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please  \\nTouch me gentl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go  \\nWhy I had t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song                                        link  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       "3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
       "4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
       "\n",
       "                                                text  \n",
       "0  Look at her face, it's a wonderful face  \\nAnd...  \n",
       "1  Take it easy with me, please  \\nTouch me gentl...  \n",
       "2  I'll never know why I had to go  \\nWhy I had t...  \n",
       "3  Making somebody happy is a question of give an...  \n",
       "4  Making somebody happy is a question of give an...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/songdata.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 76\n"
     ]
    }
   ],
   "source": [
    "vocab = set()\n",
    "for song in df[\"text\"]:\n",
    "    chars = set(song)\n",
    "    vocab = vocab.union(chars)\n",
    "vocab_size = len(vocab)\n",
    "print(\"Vocab size:\", len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = list(vocab)\n",
    "char2idx = { char:i for i,char in enumerate(chars) }\n",
    "idx2char = { i:char for i,char in enumerate(chars) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_samples(song, buffer_length):\n",
    "    tokens = song\n",
    "\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for i in range(0, len(song)):\n",
    "        if i+buffer_length+1 >= len(tokens):\n",
    "            continue\n",
    "            \n",
    "        x_train.append(tokens[i:i+buffer_length])\n",
    "        y_train.append(tokens[i+buffer_length])\n",
    "\n",
    "    return x_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data length: 133204\n",
      "X[0]: Look a\n",
      "Y[0]: t\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = [], []\n",
    "for song in df[\"text\"][:100]:\n",
    "    xs, ys = build_samples(song, 6)\n",
    "    x_train.extend(xs)\n",
    "    y_train.extend(ys)\n",
    "print(\"Training data length:\", len(x_train))\n",
    "print(\"X[0]:\", x_train[0])\n",
    "print(\"Y[0]:\", y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "\n",
    "# 80% Train, 10% Dev, 10% Test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x_train, y_train, test_size=0.2)\n",
    "X_dev, X_test, Y_dev, Y_test = train_test_split(X_test, Y_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import shuffle\n",
    "import util\n",
    "\n",
    "SEQUENCE_LENGTH = 6\n",
    "\n",
    "def generate_batches(data_length, mini_batch_size):\n",
    "    for begin in range(0, data_length, mini_batch_size):\n",
    "        end = min(begin + mini_batch_size, data_length)\n",
    "        yield begin, end\n",
    "\n",
    "def load_batch(xs, ys, begin, end):\n",
    "    batch_size = end-begin\n",
    "    \n",
    "    x_train = np.zeros((batch_size, SEQUENCE_LENGTH, vocab_size))\n",
    "    y_train = np.zeros((batch_size, vocab_size))\n",
    "    \n",
    "    xs_batch = xs[begin:end]\n",
    "    ys_batch = ys[begin:end]\n",
    "    \n",
    "    c = list(zip(xs_batch, ys_batch))\n",
    "    shuffle(c)\n",
    "    xs_batch, ys_batch = zip(*c)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        x_train[i] = util.one_hot_encode_sequence(xs_batch[i], char2idx)\n",
    "        y_train[i] = util.one_hot_encode(ys_batch[i], char2idx)\n",
    "    \n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 6, 76) (512, 76)\n"
     ]
    }
   ],
   "source": [
    "batches = generate_batches(len(X_train), 512)\n",
    "begin, end = next(batches)\n",
    "x_batch, y_batch = load_batch(X_train, Y_train, begin, end)\n",
    "print(x_batch.shape, y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 'give m' -> e\n",
      "1 ' chest' ->  \n",
      "2 'w, I'm' ->  \n",
      "3 ' move ' -> o\n",
      "4 'rust i' -> n\n",
      "5 'aking ' -> t\n",
      "6 'f you ' ->  \n",
      "7 ' I do,' ->  \n",
      "8 'mean\" ' ->  \n",
      "9 'y die ' ->  \n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    xs = ''.join(util.one_hot_decode_sequence(x_batch[i], idx2char))\n",
    "    y = util.one_hot_decode(y_batch[i], idx2char)\n",
    "    print(f\"{i} '{xs}' -> {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 512)               1206272   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 76)                38988     \n",
      "=================================================================\n",
      "Total params: 1,245,260\n",
      "Trainable params: 1,245,260\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Dropout, GRU\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "def build_model(vocab_size):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, input_shape=(SEQUENCE_LENGTH, vocab_size)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dense(vocab_size, activation='softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer=\"adam\", metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model(vocab_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = generate_batches(len(X_train), 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 1s 181us/step - loss: 1.9627 - accuracy: 0.4438\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 1s 185us/step - loss: 1.8818 - accuracy: 0.4651\n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 1s 187us/step - loss: 1.8321 - accuracy: 0.4734\n",
      "Epoch 4/4\n",
      "4096/4096 [==============================] - 1s 190us/step - loss: 1.7827 - accuracy: 0.4888\n",
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 1s 187us/step - loss: 1.9097 - accuracy: 0.4514\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 1s 194us/step - loss: 1.8290 - accuracy: 0.4780\n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 1s 189us/step - loss: 1.7937 - accuracy: 0.4832\n",
      "Epoch 4/4\n",
      "4096/4096 [==============================] - 1s 192us/step - loss: 1.7277 - accuracy: 0.5034\n",
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 1s 197us/step - loss: 1.8586 - accuracy: 0.4790\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 1s 191us/step - loss: 1.7719 - accuracy: 0.4949\n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 1s 193us/step - loss: 1.7187 - accuracy: 0.5117\n",
      "Epoch 4/4\n",
      "4096/4096 [==============================] - 1s 195us/step - loss: 1.6571 - accuracy: 0.5168\n",
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 1s 197us/step - loss: 1.8607 - accuracy: 0.4695\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 1s 204us/step - loss: 1.7524 - accuracy: 0.4998\n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 1s 213us/step - loss: 1.6988 - accuracy: 0.5078\n",
      "Epoch 4/4\n",
      "4096/4096 [==============================] - 1s 218us/step - loss: 1.6341 - accuracy: 0.5261\n",
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 1s 195us/step - loss: 1.8659 - accuracy: 0.4741\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 1s 190us/step - loss: 1.7665 - accuracy: 0.4917\n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 1s 194us/step - loss: 1.6948 - accuracy: 0.5088\n",
      "Epoch 4/4\n",
      "4096/4096 [==============================] - 1s 191us/step - loss: 1.6316 - accuracy: 0.5281\n",
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 1s 206us/step - loss: 1.9163 - accuracy: 0.4546\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 1s 196us/step - loss: 1.8031 - accuracy: 0.4795\n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 1s 211us/step - loss: 1.7246 - accuracy: 0.5088\n",
      "Epoch 4/4\n",
      "4096/4096 [==============================] - 1s 197us/step - loss: 1.6541 - accuracy: 0.5261\n",
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 1s 180us/step - loss: 1.8332 - accuracy: 0.4734\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 1s 182us/step - loss: 1.7179 - accuracy: 0.5042\n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 1s 181us/step - loss: 1.6255 - accuracy: 0.5212\n",
      "Epoch 4/4\n",
      "4096/4096 [==============================] - 1s 182us/step - loss: 1.5682 - accuracy: 0.5403\n",
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 1.8027 - accuracy: 0.4932\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 1s 179us/step - loss: 1.6788 - accuracy: 0.5122\n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 1s 180us/step - loss: 1.5932 - accuracy: 0.5386\n",
      "Epoch 4/4\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 1.5039 - accuracy: 0.5586\n",
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 1s 183us/step - loss: 1.7685 - accuracy: 0.4961\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 1s 183us/step - loss: 1.6442 - accuracy: 0.5220\n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 1s 180us/step - loss: 1.5525 - accuracy: 0.5442\n",
      "Epoch 4/4\n",
      "4096/4096 [==============================] - 1s 179us/step - loss: 1.4777 - accuracy: 0.5742\n",
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 1.7776 - accuracy: 0.4988\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 1s 179us/step - loss: 1.6474 - accuracy: 0.5254\n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 1s 180us/step - loss: 1.5601 - accuracy: 0.5505\n",
      "Epoch 4/4\n",
      "4096/4096 [==============================] - 1s 193us/step - loss: 1.4911 - accuracy: 0.5586\n",
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 1s 185us/step - loss: 1.7420 - accuracy: 0.4995\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 1s 191us/step - loss: 1.6052 - accuracy: 0.5349\n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 1s 180us/step - loss: 1.5029 - accuracy: 0.5645\n",
      "Epoch 4/4\n",
      "4096/4096 [==============================] - 1s 180us/step - loss: 1.4291 - accuracy: 0.5854\n",
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 1s 176us/step - loss: 1.7259 - accuracy: 0.5056\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 1s 183us/step - loss: 1.5808 - accuracy: 0.5437\n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 1s 179us/step - loss: 1.4953 - accuracy: 0.5654\n",
      "Epoch 4/4\n",
      "4096/4096 [==============================] - 1s 179us/step - loss: 1.4069 - accuracy: 0.5908\n",
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 1.7174 - accuracy: 0.5059\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 1.5783 - accuracy: 0.5405\n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 1s 175us/step - loss: 1.4823 - accuracy: 0.5674\n",
      "Epoch 4/4\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 1.3932 - accuracy: 0.5923\n",
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 1s 181us/step - loss: 1.7090 - accuracy: 0.5159\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 1.5732 - accuracy: 0.5464\n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 1s 197us/step - loss: 1.4765 - accuracy: 0.5818\n",
      "Epoch 4/4\n",
      "4096/4096 [==============================] - 1s 187us/step - loss: 1.3871 - accuracy: 0.5986\n",
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 1s 192us/step - loss: 1.6533 - accuracy: 0.5222\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 1s 199us/step - loss: 1.4988 - accuracy: 0.5630\n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 1s 198us/step - loss: 1.3943 - accuracy: 0.5957\n",
      "Epoch 4/4\n",
      "4096/4096 [==============================] - 1s 181us/step - loss: 1.3123 - accuracy: 0.6143\n",
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 1s 187us/step - loss: 1.6931 - accuracy: 0.5139\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 1s 191us/step - loss: 1.5412 - accuracy: 0.5522\n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 1s 215us/step - loss: 1.4304 - accuracy: 0.5811\n",
      "Epoch 4/4\n",
      "4096/4096 [==============================] - 1s 211us/step - loss: 1.3453 - accuracy: 0.6055\n",
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 1s 197us/step - loss: 1.6650 - accuracy: 0.5239\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 1s 198us/step - loss: 1.5011 - accuracy: 0.5657\n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 1s 198us/step - loss: 1.3948 - accuracy: 0.5903\n",
      "Epoch 4/4\n",
      "4096/4096 [==============================] - 1s 204us/step - loss: 1.3278 - accuracy: 0.6079\n",
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 1s 194us/step - loss: 1.6710 - accuracy: 0.5222\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 1s 201us/step - loss: 1.5102 - accuracy: 0.5642\n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 1s 204us/step - loss: 1.4054 - accuracy: 0.5837\n",
      "Epoch 4/4\n",
      "4096/4096 [==============================] - 1s 205us/step - loss: 1.3187 - accuracy: 0.6213\n",
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 1s 205us/step - loss: 1.6402 - accuracy: 0.5315\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 1s 200us/step - loss: 1.4772 - accuracy: 0.5784\n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 1s 203us/step - loss: 1.3591 - accuracy: 0.6003\n",
      "Epoch 4/4\n",
      "4096/4096 [==============================] - 1s 196us/step - loss: 1.2575 - accuracy: 0.6323\n",
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 1s 199us/step - loss: 1.6684 - accuracy: 0.5195\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 1s 197us/step - loss: 1.4876 - accuracy: 0.5688\n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 1s 198us/step - loss: 1.3626 - accuracy: 0.5994\n",
      "Epoch 4/4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 [==============================] - 1s 191us/step - loss: 1.2717 - accuracy: 0.6191\n",
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 1s 193us/step - loss: 1.7447 - accuracy: 0.5083\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 1s 190us/step - loss: 1.5472 - accuracy: 0.5498\n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 1s 200us/step - loss: 1.4328 - accuracy: 0.5845\n",
      "Epoch 4/4\n",
      "4096/4096 [==============================] - 1s 201us/step - loss: 1.3352 - accuracy: 0.6111\n",
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 1s 212us/step - loss: 1.6136 - accuracy: 0.5305\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 1s 187us/step - loss: 1.4496 - accuracy: 0.5696\n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 1s 185us/step - loss: 1.3470 - accuracy: 0.6025\n",
      "Epoch 4/4\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 1.2420 - accuracy: 0.6309\n",
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 1s 177us/step - loss: 1.6401 - accuracy: 0.5293\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 1s 178us/step - loss: 1.4700 - accuracy: 0.5725\n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 1s 187us/step - loss: 1.3455 - accuracy: 0.6113\n",
      "Epoch 4/4\n",
      "4096/4096 [==============================] - 1s 191us/step - loss: 1.2419 - accuracy: 0.6277\n",
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 1s 187us/step - loss: 1.6567 - accuracy: 0.5300\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 1s 180us/step - loss: 1.4690 - accuracy: 0.5742\n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 1s 181us/step - loss: 1.3504 - accuracy: 0.6035\n",
      "Epoch 4/4\n",
      "4096/4096 [==============================] - 1s 208us/step - loss: 1.2600 - accuracy: 0.6333\n",
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 1s 198us/step - loss: 1.6653 - accuracy: 0.5242\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 1s 195us/step - loss: 1.4692 - accuracy: 0.5750\n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 1s 210us/step - loss: 1.3528 - accuracy: 0.6050\n",
      "Epoch 4/4\n",
      "4096/4096 [==============================] - 1s 214us/step - loss: 1.2530 - accuracy: 0.6323\n",
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 1s 215us/step - loss: 1.6361 - accuracy: 0.5376\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 1s 198us/step - loss: 1.4575 - accuracy: 0.5747\n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 1s 199us/step - loss: 1.3323 - accuracy: 0.6113\n",
      "Epoch 4/4\n",
      "4096/4096 [==============================] - 1s 200us/step - loss: 1.2255 - accuracy: 0.6382\n",
      "Epoch 1/4\n",
      "67/67 [==============================] - 0s 420us/step - loss: 1.5876 - accuracy: 0.5970\n",
      "Epoch 2/4\n",
      "67/67 [==============================] - 0s 374us/step - loss: 1.3788 - accuracy: 0.6418\n",
      "Epoch 3/4\n",
      "67/67 [==============================] - 0s 420us/step - loss: 1.2554 - accuracy: 0.7313\n",
      "Epoch 4/4\n",
      "67/67 [==============================] - 0s 466us/step - loss: 0.9002 - accuracy: 0.8060\n"
     ]
    }
   ],
   "source": [
    "for begin, end in batches:\n",
    "    x_batch, y_batch = load_batch(X_train, Y_train, begin, end)\n",
    "    model.fit(x_batch, y_batch, batch_size=256, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"weights_char_rnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
